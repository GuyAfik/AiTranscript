# AI Provider Configuration
# Choose your AI provider: local (default) or openai
AI_PROVIDER=local

# Local LLM Configuration (Ollama)
# No API key needed - runs on your machine
# Install Ollama: https://ollama.ai
# Pull a model: ollama pull llama2
LOCAL_MODEL=llama2

# OpenAI Configuration (Optional)
# Only needed if using OpenAI provider
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=2000

# Whisper Configuration
# Model size options: tiny, base, small, medium, large
WHISPER_MODEL_SIZE=base
# Device options: cpu, cuda (for GPU acceleration)
WHISPER_DEVICE=cpu

# Application Settings
# Maximum file size for uploads in MB
MAX_FILE_SIZE_MB=100
# How long to keep temporary files (in hours)
TEMP_FILE_RETENTION_HOURS=1
# Supported audio formats (comma-separated)
SUPPORTED_AUDIO_FORMATS=mp3,wav,m4a,ogg,flac

# Streamlit Configuration (Optional)
# Port for the Streamlit server
STREAMLIT_SERVER_PORT=8501
# Address for the Streamlit server
STREAMLIT_SERVER_ADDRESS=localhost